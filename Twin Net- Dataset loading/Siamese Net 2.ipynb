{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import all the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combo tensor:\n",
    "\n",
    "[Batch Size x Pairs x (3x4) --> 12]  \n",
    "[Batch Size x 2 x 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # Python 3 doesn't require recursive call to self in super()\n",
    "        self.fc1 = nn.Linear(12, 24) # 1x12 input, 24 output\n",
    "        self.fc2 = nn.Linear(24, 10) # Let's try for a shallow network to see if it works\n",
    "        self.fc3 = nn.Linear(10, 1) # Output layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, combo_tensor):\n",
    "        output_0 = self.score_one_vector(combo_tensor[:,0]) # Score the first vector of the pair\n",
    "        output_1 = self.score_one_vector(combo_tensor[:,1]) # Score the second vector of the pair\n",
    "        diff = torch.abs(output_0 - output_1) # This could also be a Euclidian distance between the two vecs if abs diff doesn't work well\n",
    "        diff = self.fc3(diff) # Push diff through the final FC layer to get a single output\n",
    "        # We don't perform a sigmoid for binary CE during training b/c this will be done by the loss func automatically\n",
    "        return diff\n",
    "    \n",
    "    def score_one_vector(self, input_vec):\n",
    "        data = self.relu(self.fc1(input_vec))\n",
    "        data = self.relu(self.fc2(data))\n",
    "        return data\n",
    "    \n",
    "    def eval_forward(self, combo_tensor):\n",
    "        '''Helper function to run during evaluation.\n",
    "        Performs a sigmoid on the output of forward pass to do logistic regression'''\n",
    "#         print(self.forward(combo_tensor))\n",
    "        return self.sigmoid(self.forward(combo_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = SiameseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch code to test whether the forward model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn((100,2,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(t1,batch_size=10,shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    train_pairs = []\n",
    "    my_model.eval()\n",
    "    for i in dl:\n",
    "        output_0 = my_model.forward(i)\n",
    "#         output_1 = my_model.forward(i[:,1])\n",
    "        train_pairs.append(output_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output_pairs = []\n",
    "    my_model.eval()\n",
    "    for i in dl:\n",
    "        output_0 = my_model.eval_forward(i)\n",
    "#         output_1 = my_model.eval_forward(i[:,1])\n",
    "        output_pairs.append(output_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.nn.Sigmoid()(train_pairs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pairs[0].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.tensor([0,0,0,1,0,0,1,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output_pairs[0] > .5).to(torch.float).eq(t2.reshape(t2.shape[0],-1)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer_func = optim.Adam(my_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_loader, loss, optimizer, \n",
    "          training_device, num_epochs,\n",
    "         print_interval):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    loss_counter = 0\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(0, num_epochs):\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(training_loader):\n",
    "            \n",
    "            data, target = data.to(training_device), target.to(training_device)\n",
    "\n",
    "            # target should be a 0/1 scalar indicating match/no match\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(data)\n",
    "#             output_negative = model(data[:, 1])\n",
    "            \n",
    "            loss_value = loss(output, target)\n",
    "#             loss_negative = loss(output_negative, target[:, 1])\n",
    "            \n",
    "#             loss = loss_positive + loss_negative\n",
    "            \n",
    "            loss_value.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_counter += loss_value.item()\n",
    "            \n",
    "            if batch_idx % print_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(training_loader.dataset),\n",
    "                    100. * batch_idx / len(training_loader), loss.item()))\n",
    "                \n",
    "        epoch_loss.append(loss_counter / batch_idx)\n",
    "        loss_counter = 0\n",
    "    return epoch_loss\n",
    "\n",
    "def test(model, test_loader, loss,\n",
    "          training_device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    batch_loss_array = []\n",
    "    \n",
    "    percent_correct_array = []\n",
    "    \n",
    "#     percent_correct_negative = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(training_loader):\n",
    "            \n",
    "            data, target = data.to(training_device), target.to(training_device)\n",
    "            # target should be a 0/1 scalar indicating match/no match\n",
    "            \n",
    "            output = model(data)\n",
    "#             output_negative = model(data[:, 1])\n",
    "            # Run forward and eval forward pass sep to get loss and cats\n",
    "            loss_value = loss(output, target[:, 0])\n",
    "#             loss_negative = loss(output_negative, target[:, 1])\n",
    "            \n",
    "#             loss = loss_positive + loss_negative\n",
    "            \n",
    "            batch_loss_array.append(loss_value.item())\n",
    "            \n",
    "            num_correct = output_positive.round().eq(target).sum()\n",
    "            percent_correct = (num_correct / num_correct.shape[0]).item()\n",
    "            percent_correct_array.append(percent_correct)\n",
    "            \n",
    "            print(f'Batch Number: {batch_idx} - Percent Correct: {percent_correct}\\n')\n",
    "            \n",
    "#             if batch_idx % print_interval == 0:\n",
    "#                 print('Test Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                     epoch, batch_idx * len(data), len(training_loader.dataset),\n",
    "#                     100. * batch_idx / len(training_loader), loss.item()))\n",
    "                \n",
    "    return batch_loss_array, percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
