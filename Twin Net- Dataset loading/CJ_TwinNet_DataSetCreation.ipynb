{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# carlos dataset collection for WCST twin net\n",
    " borrows kara's program to make cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 1-hot encoded numpy array for each card\n",
    "#Kara's code generation section\n",
    "def make_cardList():\n",
    "    card_list = np.zeros((64,3,4))\n",
    "    for i, (shape, number, color) in enumerate(itertools.product(range(0,4), range(0,4), range(0,4))):\n",
    "        card_list[i][0][shape] = 1\n",
    "        card_list[i][1][number] = 1\n",
    "        card_list[i][2][color] = 1\n",
    "        \n",
    "    return card_list   \n",
    "\n",
    "def plotCards(card_list):\n",
    "    f, ax = plt.subplots(nrows=8, ncols=8, figsize=[10,10])\n",
    "    for i in range(0, card_list.shape[0]):\n",
    "        ax.flatten()[i].imshow(card_list[i])\n",
    "    # plt.tight_layout()\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 3, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = make_cardList()\n",
    "#plotCards(a)\n",
    "print(type(a))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following are functions I use to make random card lists, which together are used to create custom N-length card dataset with matching indicator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function that takes N random pairs of cards, regardless if they match or not\n",
    "\n",
    "def make_randomCardVector(setLength):\n",
    "    cards = make_cardList()\n",
    "    set1 = []\n",
    "    # cards is 64 cards by 3 dimensions by 4 values\n",
    "    \n",
    "    #create randomly shuffled index of cardlist\n",
    "    rng = default_rng() #instance the RNG\n",
    "    \n",
    "    indexes = np.arange(cards.shape[0]) #create vector of ALL possible card indexes \n",
    "    rng.shuffle(indexes) #shuffles original variable\n",
    "    \n",
    "    setIndexes = indexes[0:setLength] #extract first N values of shuffled index array for desired set length\n",
    "    \n",
    "    set1 = [cards[i] for i in setIndexes]\n",
    "    set1 = np.array(set1)\n",
    "    \n",
    "    return set1, setIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_randomCardPairs(pairSetLength):\n",
    "# take 2 random cards with replacement \n",
    " #output a stacked cardset: setlength x vector N x 3 x 4\n",
    "    cardVec1, v1shuffle = make_randomCardVector(pairSetLength)\n",
    "    cardVec2, v2shuffle = make_randomCardVector(pairSetLength)\n",
    "\n",
    "    cardDoubleVec = np.zeros((pairSetLength,2,3,4))\n",
    "    \n",
    "    cardDoubleVec[:,0,:,:] = cardVec1\n",
    "    cardDoubleVec[:,1,:,:] = cardVec2\n",
    "    \n",
    "    cardDoubleVec = torch.from_numpy(cardDoubleVec)\n",
    "    return cardDoubleVec    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cardPair_ruleMatch(cardPair, ruleNum):\n",
    "#create 3 row vector for each pair detailing if they match on axis 1-3 (represented by 1/0)\n",
    "    setLength = (cardPair.shape[0]) \n",
    "    rulematch = []\n",
    "    rulematch = [1  if np.array_equal(cardPair[i,0,ruleNum-1,:], cardPair[i,1,ruleNum-1,:]) else 0 for i in np.arange(0,setLength)]\n",
    "    rulematch = np.array(rulematch)\n",
    "    \n",
    "    rulematch = torch.from_numpy(rulematch)\n",
    "    \n",
    "    return rulematch #,setLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 3, 4])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "test = make_randomCardPairs(10)\n",
    "\n",
    "print(test.shape)\n",
    "print(type(test))\n",
    "testmatch = eval_cardPair_ruleMatch(test,1)\n",
    "print(type(testmatch), testmatch.shape)\n",
    "#, setL \n",
    "print(testmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomCardPairSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, PairSetLength):\n",
    "        \n",
    "        remainder = PairSetLength % 64\n",
    "        fullSetsNeeded = np.floor(PairSetLength/64)\n",
    "        additionalSets = fullSetsNeeded - 1\n",
    "        fullSet = 64\n",
    "        \n",
    "        self.cardset = torch.empty((1,2,3,4), dtype = torch.double) #need to make this double\n",
    "        \n",
    "        if remainder > 0:\n",
    "            self.cardset = torch.cat((self.cardset, make_randomCardPairs(remainder)))\n",
    "            \n",
    "        if fullSetsNeeded > 0:\n",
    "            self.cardset =  torch.cat((self.cardset, make_randomCardPairs(fullSet)))\n",
    "        \n",
    "        if additionalSets > 0:\n",
    "            for i in np.arange(additionalSets):\n",
    "                self.cardset = torch.cat((self.cardset, make_randomCardPairs(fullSet)),0)\n",
    "\n",
    "        self.cardset = self.cardset[1:] #remove placeholder entry\n",
    "        \n",
    "        self.match1 = eval_cardPair_ruleMatch(self.cardset, 1)\n",
    "        self.match2 = eval_cardPair_ruleMatch(self.cardset, 2)\n",
    "        self.match3 = eval_cardPair_ruleMatch(self.cardset, 3)\n",
    "    \n",
    "    #need to remove empty initialization \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cardset)\n",
    "    \n",
    "    def shape(self):\n",
    "        return self.cardset.shape\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        sample = {'cards': self.cardset[index,:,:,:],\n",
    "                  'match1': self.match1[index],\n",
    "                  'match2':self.match2[index], \n",
    "                  'match3': self.match3[index]}    \n",
    "        return sample  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation test section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testSet = randomCardPairSet(171)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.randomCardPairSet at 0x1f85a7c15b0>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([171, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(testSet.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 2.671875\n",
      "43\n",
      "2.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "x = 171\n",
    "print(x, x/64)\n",
    "remainder = x % 64\n",
    "print(remainder)\n",
    "fullSetsNeeded = np.floor(x/64)\n",
    "print(fullSetsNeeded)\n",
    "additionalSets = fullSetsNeeded - 1\n",
    "print(additionalSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "lowTest = randomCardPairSet(24)\n",
    "lowTest\n",
    "\n",
    "print(lowTest.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "fullTest = randomCardPairSet(64)\n",
    "print(fullTest.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "doubletest = randomCardPairSet(200)\n",
    "print(doubletest.shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I create dataLoader object for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "train_set = randomCardPairSet(10000)\n",
    "print(train_set.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # you can play around with this\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1f85a78b8e0>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001F85A78B8E0>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
